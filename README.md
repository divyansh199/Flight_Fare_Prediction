
# Flight Fare Prediction

## Table of Contents

- [Introduction](#introduction)
- [Project Structure](#project-structure)
- [Demo](#Demo)
- [Installation](#installation)
- [Model](#model)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)
## Introduction
Flight Fare Prediction is a sophisticated machine learning project aimed at predicting the cost of flight tickets. This project leverages various features such as the airline, departure and arrival locations, travel duration, the number of stops, and more to provide accurate fare predictions.
## Project Structure
<img src="static/image/Screenshot 2024-07-10 at 10.34.08 PM.png" height="500" />

### Directory and File Descriptions:

- **Data Cleaning/**:
  - `clean_dataset_flight.xlsx`: The cleaned dataset in Excel format.
  - `data_accessing_and_data_cleaning.ipynb`: Jupyter notebook for data accessing and cleaning.

- **EDA + Feature Engineering/**:
  - `EDA+Feature_Engineering.ipynb`: Jupyter notebook for Exploratory Data Analysis (EDA) and feature engineering.
  - `clean_dataset_flight.xlsx`: The cleaned dataset used for EDA and feature engineering.
  - `report.html`: HTML report generated from the EDA.

- **Model Creation/**:
  - `Model_Creation.ipynb`: Jupyter notebook for model creation.
  - `final_dataset.xlsx`: The final dataset used for model creation.
  - `.DS_Store`: A system file automatically generated by macOS.

- **static/**:
  - **image/**: Directory for images used in the web app.
  - **css/**: Directory for CSS files.
    - `style.css`: Stylesheet for the web app.

- **templates/**:
  - `home.html`: HTML template for the home page of the web app.

- **.DS_Store**:
  - A system file automatically generated by macOS.

- **.gitignore**:
  - Specifies files and directories to be ignored by Git.

- **Flight_Fare.xlsx**:
  - The original dataset in Excel format.

- **PRCP-1025-FlightPricePrediction.docx**:
  - A project report or documentation file in Word format.

- **Procfile**:
  - A file for declaring the commands that are run by the Heroku app.

- **app.py**:
  - The main application script for running the web app.

- **flight_fare_rfr.pkl**:
  - The trained Random Forest Regressor model saved as a pickle file.

- **requirements.txt**:
  - List of Python dependencies required for the project.

- **README.md**:
  - Project documentation.

## Installation



```bash
  conda create -p venv
```

```bash
  pip install -r requirements.txt
```

## Demo
<img src="static/image/ScreenRecording2024-07-10at9.04.07PM-ezgif.com-speed.gif" height="500" />

## Tech Stack

<p align="center">
    <img src="https://www.python.org/static/community_logos/python-logo.png" height="100" />
    <img src="https://flask.palletsprojects.com/en/2.0.x/_images/flask-logo.png" height="100" />
    <img src="https://gunicorn.org/logo.png" height="100" />
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/320px-Scikit_learn_logo_small.svg.png" height="100" />
    <img src="https://numpy.org/images/logos/numpy.svg" height="100" />
    <img src="https://pandas.pydata.org/static/img/pandas.svg" height="100" />
    <img src="https://seaborn.pydata.org/_static/logo-wide-lightbg.svg" height="100" />
</p>


## Badges
![Flask](https://img.shields.io/badge/Flask-2.0-green)
![Python](https://img.shields.io/badge/Python-3.6%2B-blue)

## Model
<img src="https://upload.wikimedia.org/wikipedia/commons/6/69/XGBoost_logo.png" alt="XGBoost Logo" width="200"/>

**XGBoost**:
- **Type**: XGBoost is an ensemble learning method based on decision trees, specifically gradient boosting.
- **Performance**: It is known for its efficiency and effectiveness in handling large datasets and achieving state-of-the-art results in various machine learning competitions.
- **Key Features**:
  - **Regularization**: XGBoost includes regularization techniques to prevent overfitting, such as L1 and L2 regularization.
  - **Gradient Boosting**: It builds multiple decision trees sequentially, where each new tree tries to correct errors made by the previous one.
  - **Cross-validation**: XGBoost supports built-in cross-validation to optimize model parameters.
  - **Parallelization**: It can efficiently utilize multicore CPUs during training for faster execution.
- **Applications**: XGBoost is widely used for classification, regression, and ranking problems in areas such as finance, healthcare, and technology.
- **Language Support**: It is implemented in several programming languages, including Python, R, Java, and Julia.


<img src="static/image/Screenshot 2024-07-10 at 11.29.33 PM.png" height="500" />

<img src="static/image/Screenshot 2024-07-10 at 11.31.51 PM.png" height="500" />

<img src="static/image/Screenshot 2024-07-10 at 11.31.18 PM.png" height="500" />

<img src="static/image/Screenshot 2024-07-10 at 11.30.30 PM.png" height="500" />